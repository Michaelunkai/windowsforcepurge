#pip install joblib

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Load the data from the CSV file
data = pd.read_ ('data. ')

# Display the first five rows of the data
print("Data preview:")
print(data.head())

# Split the data into features (X) and labels (y)
X = data[['Feature1', 'Feature2', 'Feature3']]
y = data['Label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a RandomForestClassifier object
clf = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
clf.fit(X_train, y_train)

# Save the trained model to a file
joblib.dump(clf, 'random_forest_model.pkl')

# Load the model from the file
loaded_clf = joblib.load('random_forest_model.pkl')

# Make predictions on the test set
y_pred = loaded_clf.predict(X_test)

# Display the predictions
print("Predictions:")
print(y_pred)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Feature importance
importances = loaded_clf.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print("Feature Importances:")
print(feature_importance_df)

# Hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_features': ['sqrt', 'log2'],  # Removed 'auto'
    'max_depth': [4, 6, 8, None],
    'criterion': ['gini', 'entropy']
}

grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
print("Best Parameters:")
print(best_params)

# Train the model with the best parameters
best_clf = grid_search.best_estimator_
best_clf.fit(X_train, y_train)

# Save the best model to a file
joblib.dump(best_clf, 'best_random_forest_model.pkl')

# Load the best model from the file
loaded_best_clf = joblib.load('best_random_forest_model.pkl')

# Make predictions and evaluate
best_y_pred = loaded_best_clf.predict(X_test)
best_accuracy = accuracy_score(y_test, best_y_pred)
print(f"Best Accuracy: {best_accuracy}")

# Plot confusion matrix manually
cm = confusion_matrix(y_test, best_y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt. ow()

# ROC Curve
y_prob = loaded_best_clf.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)
auc = roc_auc_score(y_test, y_prob)

plt.figure()
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {auc:.2f})')
plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt. ow()

