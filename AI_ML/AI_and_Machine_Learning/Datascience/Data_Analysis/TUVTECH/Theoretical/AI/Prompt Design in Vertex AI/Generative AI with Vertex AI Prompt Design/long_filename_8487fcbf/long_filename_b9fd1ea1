Transcript
00:00
The following case study outlines how our AI principles and review processes shaped Google Cloud’s approach to facial recognition technology Let's start with the outcome of our
00:10
review In 2019 Google Cloud launched Celebrity Recognition, a tightly scoped API to Media & Entertainment customers looking to tag celebrities in their professional licensed media content.
00:24
Searching through video content has been a difficult and time-intensive task without expensive tagging processes.
00:31
This makes it difficult for creators to organize their content and offer personalized experiences.
00:37
The Celebrity Recognition API is a pre-trained AI model — meaning it’s not customizable— that’s able
00:43
to recognize thousands of popular actors and athletes from around the world based on licensed images.
00:50
This is Google Cloud’s first enterprise product with facial recognition.
00:53
So, how did we get here?
00:57
Facial recognition was identified as a key concern for potential unfair bias.
01:02
In early 2016, Cloud leadership decided facial recognition would not be a part of the Cloud Vision API offering, despite it being a top request from our customers.
01:13
To explore this further, we took facial recognition through an early iteration of our AI Principles review process.
01:20
These reviews gave us the open forum and time to think critically about the research, societal context, and challenges
01:26
of the technology We’ve seen how useful the spectrum of face-related technologies can be for people and for society overall.
01:36
They can make products safer and more secure like using face authentication to control access to sensitive information There are uses with tremendous
01:44
social good, such as nonprofits using facial recognition to fight trafficking against minors But it’s important that these technologies are developed thoughtfully and responsibly.
01:58
Google shares many of the widely-discussed concerns over the misuse of facial recognition technology, namely: It needs
02:03
to be fair, so it doesn’t reinforce or amplify existing biases, especially where this might impact underrepresented groups.
02:14
It should not be used in surveillance that violates internationally accepted norms And it needs to protect people’s privacy, providing the right level of transparency and control.
02:25
To reduce the potential for misuse and make the technology available for an enterprise use case aligned
02:29
with our AI principles, Google decided to pursue a tightly scoped facial recognition application for celebrity recognition.
02:33
Google decided to pursue a tightly scoped facial recognition application for celebrity recognition.
02:38
Google decided to pursue a tightly scoped facial recognition application for celebrity recognition.
02:40
To prepare for launch readiness of the Celebrity Recognition API, along with our own internal review processes, we sought help from external experts and civil rights leaders.
02:50
We recognized that our lived experience wouldn’t necessarily align with the lived experience of impacted people, and we needed help incorporating those experiences and
03:00
concerns into our review Systemic underrepresentation of black and minoritized actors in society was a key factor in our evaluation given the product’s intended use.
03:12
To focus even further on potential impacts we engaged with an external human rights consultancy— called Business for Social Responsibility, or BSR— to conduct an in-depth Human Rights Impact Assessment.
03:27
Engaging with BSR played an essential role in shaping the API’s capabilities and policies, integrating human rights considerations throughout the product development lifecycle.
03:37
It also revealed where the solution needed additional oversight and validated our earlier decision not to offer general purpose facial recognition APIs.
03:47
Their full report is publicly available and can be found in the resources section.
03:55
Based on BSR’s recommendations Google implemented a number of safeguards, including: Making the Celebrity Recognition API available only to qualifying customers behind an allow list.
04:07
The database of “Celebrity” individuals is carefully defined and restricted to a predefined list.
04:14
An opt-out policy is implemented to enable celebrities to remove themselves from the list.
04:20
And an expanded terms of service apply to the API.
04:24
These measures serve to avoid and mitigate potential harms and provide Google with a firm basis to reduce risks to human rights.
04:33
Another key step in Google’s review of the Celebrity Recognition API was a series of fairness analyses.
04:40
Fundamentally, these fairness tests sought to evaluate the performance of the API in terms of Recall and Precision.
04:48
In other words, we evaluated the performance of the API both for individual skin tone and gender groups, but also
04:55
for the combination of those groups —for example, for women with darker skin tones, or men with lighter skin tones.
05:04
Over three separate fairness tests, we found errors between our training datasets and one of the benchmarks based on skin tone.
05:12
Those errors gave us pause and we decided to take a deeper look at the root causes.
05:17
The first thing we checked was whether the skin tone labels in our dataset were accurate.
05:23
It was discovered they weren’t completely accurate for medium- and darker- skinned people.
05:28
We relabelled the skin tones according to the Fitzpatrick skin type scale as used in the seminal “‘Gender Shades”’ research by Joy Buolamwini and Timnit Gebru.
05:39
This research evaluated bias present in automated facial analysis algorithms and datasets with respect to skin tone and gender.
05:48
Relabelling the skin tones reduced error rates, but we found further discrepancies.
05:53
A small subset of actors represented a significant proportion of the total missed identifications in the evaluation datasets Especially for darker-skinned men Knowing the majority of error
06:04
rates were affecting a select few actors we looked at the actors with the largest number of errors and found they had nearly a 100% false rejection rate.
06:15
Due to the reduced scope of the Celebrity Recognition API we were able to go one by one through the test set and gallery to determine what the problem was.
06:24
We found that for three black actors our celebrity gallery had images of them as adults while the training set had images of them as much younger actors.
06:32
Our model could not recognize the adult actors as the younger characters they had played years prior.
06:39
In this instance, we were able to correct that problem by expanding the training dataset to
06:44
include images of celebrities at many different points in their careers and at different ages .
06:49
This removed the discrepancy between error rates.
06:53
This experience drove home the importance of taking the time to look at the overall context of the solution Namely, the issues of representation in media.
07:03
Only with an appreciation of that context, tightly scoping the solution, and after rigorously testing and improving the API for fairness were we able to get comfortable launching the API.
07:14
This is an example of why responsible development of AI leads to successful integration of AI.
07:22
In mid 2020 we welcomed the news that other technology companies were limiting or exiting their facial recognition business given the wider concerns about the technology.
07:32
Ultimately our AI governance process allowed us to research and scope a product that aligned with our AI principles.
07:38
and scope a product that aligned with our AI principles.
07:41
Today, Google has released the Monk Skin Tone (MST) Scale, a more refined skin tone scale that will help us better understand representation in imagery.
