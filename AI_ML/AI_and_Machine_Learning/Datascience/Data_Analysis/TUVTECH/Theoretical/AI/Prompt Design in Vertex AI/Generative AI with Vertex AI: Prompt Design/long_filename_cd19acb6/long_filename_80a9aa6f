Transcript
00:00
Our journey to operationalize Google’s AI principles required the collaboration and diligent work of many.
00:07
We continue to learn a lot about this process—both from our successes and challenges— and
00:11
are committed to iterating, evolving, and sharing along the way to help you on your journey.
00:18
Next, we’ll explore some challenges we often encounter during the AI principles process, all of which we suspect might not be unique challenges to Google alone.
00:30
The first key challenge is that measuring the effectiveness of responsible AI is not straightforward.
00:36
The first key challenge is that measuring the effectiveness of responsible AI is not straightforward.
00:38
Assessing how mitigations address ethical issues can be more difficult than assessing technical performance.
00:42
In a sector that values impact metrics and quantifiable results, measuring the effectiveness of mitigations that prevent a potential harm or issue from happening is not easy.
00:54
Because of this, the metrics that indicate success for responsible innovation may look a bit different from traditional business metrics.
01:02
For example, we track issues and their related mitigations, and how they are implemented in the product.
01:08
We also look at the impact our AI governance has on building customer trust and accelerating deal success.
01:15
Another measure of effectiveness is gathering end -users' experiences and perceptions through surveys and customer feedback.
01:22
These types of metrics help to track impact, identify trends, and establish precedents.
01:30
Another challenge is around ethical dilemmas.
01:33
When applying our principles, ethical dilemmas often arise rather than clear decisions between right and wrong.
01:40
Members of the review committee, each with their individual interpretation of the AI principles, lived experiences and expertise, apply their own values to ethical issues.
01:52
This can create a tension between different values that fosters a lot of debate.
01:56
It’s important to remember that these dilemmas, and resulting deliberations, are a core goal of an AI Principles review.
02:03
Working through these dilemmas requires open and honest conversations, and an understanding that these aren't easy decisions to make.
02:11
These conversations ultimately help identify and assess the trade-offs between our choices.
02:18
Yet another challenge is that applying our AI Principles can seem subjective or culturally relative.
02:24
A few ways we reduce this subjectivity include: Having a well-defined AI Principles review and decision-making process to foster trust in that process.
02:35
Grounding the review in technical, research, and business realities connects the mitigations to real world issues.
02:42
Documenting how decisions were made can provide necessary transparency and ensure accountability for the review team and beyond.
02:49
Keeping a comprehensive record of prior precedents is important to ensure consistency, by assessing whether the case at hand is relevantly different from cases in the past.
03:00
An additional challenge we face is getting direct input from external domain experts and affected groups.
03:08
This is critical, but not easy and we want to recognize that the process of doing so can be difficult.
03:14
No one person can represent the viewpoints of the group of people you are trying to represent.
03:20
The goal is to hear as wide a range of voices as possible.
03:24
so that products are made for everyone.
03:27
These are just a few examples of the many challenges that can be faced when developing responsible AI.
03:33
On the responsible AI journey, there will always be issues and challenges, striving to minimize and mitigate them starts with that recognition.
