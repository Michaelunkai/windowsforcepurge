
Anthropic Publishes the 'System Prompts' Powering Claude AI Models

Generative AI models, like Claude by Anthropic, aren’t truly human-like in their intelligence or personality. They are statistical systems designed to predict the most likely next words in a sentence. However, like interns in a workplace, they follow instructions and strive to please, including through initial "System Prompts" that load the models with their core attributes and what they should or shouldn't do.

Every generative AI company, from OpenAI to Anthropic, uses 'System Prompts' to prevent (or at least try to prevent) models from behaving inappropriately and to guide the overall tone and emotion of the model's responses. For instance, a prompt might instruct a model to be polite but not apologetic, or to be upfront about its limitations.

Typically, companies keep these 'System Prompts' closely guarded, likely for competitive reasons, but perhaps also because knowing the prompts could reveal ways to bypass them. Despite this, Anthropic, in its ongoing effort to position itself as an ethical and transparent AI provider, has released the System Prompts for its latest models: Claude 3 Opus, Claude 3.5 Sonnet, and Claude 3.5 Haiku, available in the Claude apps for iOS, Android, and online.

Alex Albert, head of Anthropic’s developer relations, mentioned in a post on X that the company plans to make this kind of disclosure a regular practice as it updates and improves its System Prompts.

The latest prompts, dated July 12, clearly outline what the Claude models cannot do. For example, “Claude cannot open URLs, links, or videos.” Facial recognition is strictly forbidden; the System Prompt for Claude Opus instructs the model to “always respond as if it is completely face blind” and to “avoid identifying or naming any humans in [images].”

The prompts also describe specific personality traits and attributes that Anthropic wants Claude models to exhibit. For example, the prompt for Claude 3 Opus states that Claude should appear “very intelligent and intellectually curious,” and “enjoy hearing what humans think about a topic and engaging in discussion on a wide range of subjects.” It also instructs Claude to approach controversial topics with impartiality and objectivity, providing “careful thoughts” and “clear information”—and never to begin responses with “Certainly” or “Definitely.”

With these new System Prompts—the first of their kind from a major AI company—Anthropic is putting pressure on its competitors to follow suit. It will be interesting to see if others will publish theirs as well.
